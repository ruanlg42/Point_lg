# Point_lg - çƒ­ä¼ å¯¼å‚æ•°é¢„æµ‹æ·±åº¦å­¦ä¹ æ¡†æ¶

## é¡¹ç›®ç®€ä»‹

Point_lg æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„çƒ­ä¼ å¯¼å‚æ•°é¢„æµ‹ç³»ç»Ÿ,ä¸“é—¨ç”¨äºä»æ¸©åº¦æ—¶åºæ•°æ®ä¸­é¢„æµ‹ææ–™çš„çƒ­æ‰©æ•£ç³»æ•°(thermal effusivity, e)ã€‚è¯¥é¡¹ç›®å®ç°äº†å¤šç§å…ˆè¿›çš„æ—¶åºæ¨¡å‹æ¶æ„,åŒ…æ‹¬ Transformerã€Mambaã€VAE ç­‰,å¹¶èå…¥äº†ç‰©ç†å…ˆéªŒçŸ¥è¯†ä»¥æå‡é¢„æµ‹ç²¾åº¦ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ”¥ å¤šæ ·åŒ–çš„æ¨¡å‹æ¶æ„

é¡¹ç›®å®ç°äº† 10+ ç§æ·±åº¦å­¦ä¹ æ¨¡å‹,æ¶µç›–ä»¥ä¸‹ç±»å‹:

1. **ç»å…¸æ¶æ„**
   - Transformer: åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„æ—¶åºæ¨¡å‹
   - CNN1D: ä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œ

2. **ç‰©ç†å…ˆéªŒå¢å¼ºæ¨¡å‹**
   - PhysicsInformedCNN: èå…¥ç‰©ç†ç‰¹å¾çš„ CNN (4é€šé“è¾“å…¥: T, á¹ª, t^(-1/2), Î”t)
   - PhysicsInformedTransformer: ç‰©ç†å¢å¼º Transformer
   - EnhancedPhysicsTransformer: å¢å¼ºç‰ˆ,åŒ…å«æ®‹å·®è¿æ¥å’Œè‡ªé€‚åº”æ—¶åºæ³¨æ„åŠ›æ± åŒ–

3. **é«˜æ•ˆ Mamba æ¶æ„** (O(L) æ—¶é—´å¤æ‚åº¦ vs Transformer çš„ O(LÂ²))
   - MambaPhysicsModel: åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹çš„é«˜æ•ˆæ¶æ„
   - EnhancedMambaPhysicsModel: å¢å¼ºç‰ˆ Mamba,æ”¯æŒå¤šå°ºåº¦ç‰¹å¾èåˆ
   - HybridMambaTransformer: Mamba + Transformer æ··åˆæ¶æ„

4. **å˜åˆ†è‡ªç¼–ç å™¨ (VAE) ç³»åˆ—**
   - TimeVAE1D_Mamba: åŸºäº Mamba çš„æ—¶åº VAE
   - TimeVAE1D_Transformer: åŸºäº Transformer çš„æ—¶åº VAE
   - TimeVAE1D_HybridMambaTransformer: æ··åˆæ¶æ„ VAE
   - **TimeVAE1D_HybridMambaTransformer_Residual**: â­ æ®‹å·®é‡å»º VAE (æ¨è)
   - TimeVAE1D_StageAware: æ—¶åºåˆ†æ®µæ„ŸçŸ¥ VAE
   - TimeVAE1D_SSTEncoder_Residual: åŸºäº SST ç¼–ç å™¨çš„ VAE

5. **å…¶ä»–æ¶æ„**
   - PhysTCN: ç‰©ç†ä¿¡æ¯æ—¶åºå·ç§¯ç½‘ç»œ
   - TimeVAE1D_Mamba_PhysicsDecoder: ç‰©ç†åŸºå‡½æ•°è§£ç å™¨ VAE

### ğŸ“Š æ™ºèƒ½æ•°æ®å¤„ç†

- **è‡ªé€‚åº”æ•°æ®æ‰“åŒ…**: æ”¯æŒä»»æ„æ•°é‡çš„æµ‹æ¸©ç‚¹ (4åˆ—ã€13åˆ—æˆ–æ›´å¤š)
- **å¤šç‚¹ç‹¬ç«‹é‡‡æ ·**: æ¯ä¸ªæµ‹æ¸©ç‚¹ä½œä¸ºç‹¬ç«‹æ ·æœ¬,é€šè¿‡ `thickness+åºå·` åŒºåˆ†
- **è‡ªåŠ¨å½’ä¸€åŒ–**: æ¸©åº¦å½’ä¸€åŒ– + log(e) å˜æ¢å¤„ç†åæ–œåˆ†å¸ƒ
- **ç‰©ç†ç‰¹å¾å·¥ç¨‹**: 
  - é«˜æ–¯æ»¤æ³¢å¹³æ»‘ (sigma=2)
  - 4é€šé“ç‰©ç†ç‰¹å¾: T_tilde (ç›¸å¯¹æ¸©åº¦), T_dot (æ¸©åº¦å¯¼æ•°), t^(-1/2) (ç‰©ç†å…ˆéªŒ), Î”t (é‡‡æ ·é—´éš”)

### ğŸ¯ é«˜çº§è®­ç»ƒç‰¹æ€§

- **åˆ†æ®µåŠ æƒæŸå¤±**: é’ˆå¯¹ä¸åŒ e å€¼èŒƒå›´é‡‡ç”¨ä¸åŒæƒé‡,é˜²æ­¢å¼‚å¸¸é«˜å€¼
- **VAE æŸå¤±å‡½æ•°**: é‡å»ºæŸå¤± + KLæ•£åº¦ + å‚æ•°é¢„æµ‹æŸå¤± + åˆå€¼çº¦æŸ
- **å¤š GPU è®­ç»ƒ**: è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å¤šä¸ª GPU (æ”¯æŒ DataParallel)
- **å­¦ä¹ ç‡è°ƒåº¦**: ReduceLROnPlateau è‡ªé€‚åº”è°ƒæ•´
- **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- **Checkpoint ä¿å­˜**: è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹å’Œé…ç½®

### ğŸš€ çµæ´»çš„é¢„æµ‹æ¥å£

- **ä»æ–‡æœ¬æ–‡ä»¶é¢„æµ‹**: æ”¯æŒå¤šç§æ ¼å¼çš„æ¸©åº¦æ•°æ®æ–‡ä»¶
- **æ‰¹é‡ GIF é¢„æµ‹**: ä»çƒ­æˆåƒ GIF ä¸­æå–æ¸©åº¦å¹¶é¢„æµ‹
- **è‡ªåŠ¨æ’å€¼**: å¤„ç†ä¸åŒæ—¶é—´æ­¥é•¿çš„æ•°æ®
- **å¯è§†åŒ–è¾“å‡º**: ç”Ÿæˆé¢„æµ‹ç»“æœå›¾è¡¨å’Œå¯¹æ¯”æ•°æ®

## é¡¹ç›®ç»“æ„

```
Point_lg/
â”œâ”€â”€ config.yaml                          # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ model.py                             # æ‰€æœ‰æ¨¡å‹æ¶æ„å®šä¹‰ (4326è¡Œ)
â”œâ”€â”€ dataset.py                           # æ•°æ®é›†åŠ è½½å™¨
â”œâ”€â”€ train.py                             # è®­ç»ƒè„šæœ¬ (1578è¡Œ)
â”œâ”€â”€ predict_from_txt.py                  # ä»txtæ–‡ä»¶é¢„æµ‹
â”œâ”€â”€ predict_gif.py                       # ä»GIFæ–‡ä»¶é¢„æµ‹ (964è¡Œ)
â”œâ”€â”€ data_transfer_multipoint_flexible.py # æ•°æ®æ‰“åŒ…å·¥å…·
â”œâ”€â”€ plot_temperature_curves.py           # æ¸©åº¦æ›²çº¿å¯è§†åŒ–
â”œâ”€â”€ plot_quick.py                        # å¿«é€Ÿç»˜å›¾å·¥å…·
â”œâ”€â”€ test_4columns_predict.py             # 4åˆ—æ•°æ®é¢„æµ‹æµ‹è¯•
â”œâ”€â”€ gif_test/                            # GIFæµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ newdata_30hz/                    # 30Hzé‡‡æ ·æ•°æ®
â”‚   â”œâ”€â”€ newdata_30hz_vaehybrid/          # VAEæ··åˆæ¨¡å‹æ•°æ®
â”‚   â”œâ”€â”€ newdata_a/, newdata_aa/          # æµ‹è¯•æ•°æ®é›†
â”‚   â”œâ”€â”€ newnewnew_30hz/                  # æ–°30Hzæ•°æ®
â”‚   â”œâ”€â”€ newnewnew_shape/                 # å½¢çŠ¶æ•°æ®
â”‚   â””â”€â”€ past_data/                       # å†å²æ•°æ®
â”œâ”€â”€ test_code/                           # æµ‹è¯•å’Œåˆ†æè„šæœ¬
â”‚   â”œâ”€â”€ analyze_data_mismatch.py
â”‚   â”œâ”€â”€ check_training_data.py
â”‚   â”œâ”€â”€ compare_filters.py
â”‚   â”œâ”€â”€ debug_pth_data.py
â”‚   â”œâ”€â”€ grid_search.py
â”‚   â””â”€â”€ vae_*.py                         # VAEç›¸å…³æµ‹è¯•
â”œâ”€â”€ comparison_results/                  # å¯¹æ¯”ç»“æœ
â””â”€â”€ results/                             # è®­ç»ƒç»“æœè¾“å‡ºç›®å½•
```

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
# æ ¸å¿ƒä¾èµ–
Python >= 3.8
PyTorch >= 1.10
CUDA >= 11.0 (å¯é€‰,ç”¨äºGPUåŠ é€Ÿ)

# å¿…éœ€åº“
pip install torch torchvision
pip install pyyaml numpy scipy pillow matplotlib tqdm
pip install mamba-ssm  # Mambaæ¨¡å‹å¿…éœ€
pip install tensorboard  # è®­ç»ƒå¯è§†åŒ–
```

### 1. æ•°æ®å‡†å¤‡

å°†åŸå§‹æ•°æ®æ‰“åŒ…ä¸º PyTorch æ ¼å¼:

```bash
python data_transfer_multipoint_flexible.py
```

æ•°æ®æ ¼å¼è¦æ±‚:
- `*_parameters.yaml`: åŒ…å«ææ–™å‚æ•° (Lambda, T0, T1, c, e, p, thickness, time)
- `*_mph.txt`: æ¸©åº¦æ—¶åºæ•°æ® (æ—¶é—´ + Nåˆ—æ¸©åº¦)

### 2. é…ç½®æ¨¡å‹

ç¼–è¾‘ `config.yaml` æ–‡ä»¶:

```yaml
# ä»»åŠ¡é…ç½®
task:
  prefix: AAA_Final_setup        # ä»»åŠ¡å‰ç¼€
  suffix: null                   # ä»»åŠ¡åç¼€

# æ•°æ®é…ç½®
data:
  dataset_path: /path/to/thermal_dataset_multipoint.pth
  normalize_temp: true           # æ¸©åº¦å½’ä¸€åŒ–
  use_log_e: true                # eå€¼å¯¹æ•°å˜æ¢
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  batch_size: 4096
  total_time: 5.0                # æ€»é‡‡æ ·æ—¶é—´(ç§’)
  delta_t: 0.03333333333333333   # é‡‡æ ·é—´éš”(ç§’)
  seq_len: 151                   # åºåˆ—é•¿åº¦

# æ¨¡å‹é…ç½® (é€‰æ‹©ä¸€ä¸ª)
model:
  type: timevae1d_hybrid_mamba_transformer_residual  # æ¨è
  timevae1d_hybrid_mamba_transformer_residual:
    C_in: 1                      # è¾“å…¥é€šé“æ•°
    latent_dim: 256              # éšç©ºé—´ç»´åº¦
    d_model: 256                 # æ¨¡å‹ç»´åº¦
    n_mamba: 3                   # Mambaå±‚æ•°
    n_transformer: 3             # Transformerå±‚æ•°
    nhead: 4                     # æ³¨æ„åŠ›å¤´æ•°
    d_state: 16                  # SSMçŠ¶æ€ç»´åº¦
    d_conv: 4                    # å±€éƒ¨å·ç§¯å®½åº¦
    expand: 2                    # æ‰©å±•å› å­
    dropout: 0.2                 # Dropoutç‡
    decoder_base: 128            # è§£ç å™¨åŸºç¡€é€šé“æ•°
    lambda_ic: 0.5               # åˆå€¼çº¦æŸæƒé‡

# æŸå¤±å‡½æ•°é…ç½®
loss:
  threshold_1: 10000.0           # ç¬¬ä¸€é˜ˆå€¼
  threshold_2: 30000.0           # ç¬¬äºŒé˜ˆå€¼
  low_weight: 1                  # ä½å€¼æƒé‡
  mid_weight: 1                  # ä¸­å€¼æƒé‡
  high_weight: 1                 # é«˜å€¼æƒé‡

# è®­ç»ƒé…ç½®
training:
  epochs: 1000
  learning_rate: 0.001
  weight_decay: 0.0001
  device: cuda
  seed: 42
```

### 3. è®­ç»ƒæ¨¡å‹

```bash
# å•GPUè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0 python train.py

# å¤šGPUè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3 python train.py
```

è®­ç»ƒè¿‡ç¨‹ä¼šè‡ªåŠ¨:
- ç”Ÿæˆä»»åŠ¡åç§° (å‰ç¼€_æ—¶é—´æˆ³_æ¨¡å‹å‚æ•°)
- ä¿å­˜æ£€æŸ¥ç‚¹åˆ° `results/model_result/ä»»åŠ¡åç§°/`
- è®°å½•è®­ç»ƒæ—¥å¿—å’Œ TensorBoard æ•°æ®
- ä¿å­˜æœ€ä½³æ¨¡å‹å’Œé…ç½®æ–‡ä»¶

### 4. é¢„æµ‹

#### ä»æ–‡æœ¬æ–‡ä»¶é¢„æµ‹

ç¼–è¾‘ `predict_from_txt.py` ä¸­çš„è·¯å¾„:

```python
TXT_PATH = '/path/to/temperature_data.txt'
MODEL_PATH = '/path/to/best_model.pth'
CONFIG_PATH = '/path/to/config_used.yaml'
```

è¿è¡Œé¢„æµ‹:

```bash
python predict_from_txt.py
```

è¾“å‡ºç¤ºä¾‹:
```
PREDICTED THERMAL EFFUSIVITY: 5678.45 JÂ·mâ»Â²Â·Kâ»Â¹Â·sâ»Â¹/Â²
```

#### ä» GIF é¢„æµ‹

```bash
python predict_gif.py \
  --gif_dir /path/to/gif_folder \
  --model_path /path/to/best_model.pth \
  --config_path /path/to/config_used.yaml \
  --output_dir /path/to/output
```

## æ¨¡å‹æ¶æ„è¯¦è§£

### TimeVAE1D_HybridMambaTransformer_Residual (æ¨è)

è¿™æ˜¯å½“å‰æ€§èƒ½æœ€ä¼˜çš„æ¨¡å‹æ¶æ„,é‡‡ç”¨äº†ä»¥ä¸‹åˆ›æ–°:

**æ¶æ„ç‰¹ç‚¹:**
1. **æ··åˆç¼–ç å™¨**: åº•å±‚ä½¿ç”¨ Mamba (O(L) å¤æ‚åº¦)å¿«é€Ÿå»ºæ¨¡,é¡¶å±‚ä½¿ç”¨ Transformer è¿›è¡Œå…¨å±€ç²¾ç»†åŒ–
2. **æ®‹å·®é‡å»º**: é€šè¿‡é¢„æµ‹æ®‹å·®è€Œéç»å¯¹æ¸©åº¦,æå‡é‡å»ºç²¾åº¦
3. **åˆå€¼çº¦æŸ**: æ·»åŠ  Î»_ic æŸå¤±é¡¹,ç¡®ä¿æ®‹å·®åœ¨åˆå§‹æ—¶åˆ»æ¥è¿‘0
4. **é«˜æ–¯æ»¤æ³¢é¢„å¤„ç†**: å¹³æ»‘è¾“å…¥åºåˆ—,å‡å°‘å™ªå£°å¹²æ‰°

**å‰å‘æµç¨‹:**
```
è¾“å…¥ [B, 1, T] 
  â†“ é«˜æ–¯æ»¤æ³¢ (sigma=2)
  â†“ 1D Conv [B, d_model, T]
  â†“ Mamba Layers (n_mamba) [B, d_model, T]
  â†“ Transformer Layers (n_transformer) [B, d_model, T]
  â†“ Pooling â†’ [B, d_model]
  â†“ FC â†’ [B, latent_dim*2] â†’ (Î¼, log_ÏƒÂ²)
  â†“ Reparameterization â†’ z [B, latent_dim]
  â†“ Decoder (Conv1DTranspose) â†’ Î”x [B, 1, T] (æ®‹å·®)
  â†“ x_recon = x_smooth + Î”x
  â”” Parameter Head â†’ e [B, 1]
```

**æŸå¤±å‡½æ•°:**
```
L_total = L_recon + Î²Â·L_KL + Î»_eÂ·L_e + Î»_icÂ·L_ic

å…¶ä¸­:
- L_recon = MSE(x_recon, x_true)
- L_KL = -0.5Â·Î£(1 + log_ÏƒÂ² - Î¼Â² - ÏƒÂ²)
- L_e = WeightedMSE(e_pred, e_true)
- L_ic = |Î”x[0]|  (æ®‹å·®åˆå€¼çº¦æŸ)
```

### Mamba vs Transformer

| ç‰¹æ€§ | Mamba | Transformer |
|------|-------|-------------|
| æ—¶é—´å¤æ‚åº¦ | O(L) | O(LÂ²) |
| ç©ºé—´å¤æ‚åº¦ | O(LÂ·d) | O(LÂ²+LÂ·d) |
| é•¿åºåˆ—å¤„ç† | âœ… é«˜æ•ˆ | âŒ æ…¢ |
| å…¨å±€ä¾èµ– | âœ… SSM | âœ… æ³¨æ„åŠ› |
| å¹¶è¡ŒåŒ– | âš ï¸ éƒ¨åˆ† | âœ… å®Œå…¨ |

**æ··åˆæ¶æ„ä¼˜åŠ¿**: ç»“åˆ Mamba çš„é«˜æ•ˆæ€§å’Œ Transformer çš„å…¨å±€å»ºæ¨¡èƒ½åŠ›

## é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰ç‰©ç†ç‰¹å¾

åœ¨ `model.py` ä¸­ä¿®æ”¹ `_preprocess_sequence` æ–¹æ³•:

```python
def _preprocess_sequence(self, temp_sequence):
    # æ·»åŠ è‡ªå®šä¹‰ç‰©ç†ç‰¹å¾
    # Channel 1: T_tilde (ç›¸å¯¹æ¸©åº¦)
    T_tilde = T_smooth - T_smooth[:, 0:1]
    
    # Channel 2: T_dot (æ¸©åº¦å¯¼æ•°)
    T_dot = (T_smooth[:, 1:] - T_smooth[:, :-1]) / self.delta_t
    
    # Channel 3: è‡ªå®šä¹‰ç‰¹å¾ (å¦‚ t^(-1/2))
    t_inv_sqrt = 1.0 / torch.sqrt(time_steps)
    
    # Channel 4: å…¶ä»–ç‰¹å¾
    # ...
    
    return torch.stack([...], dim=1)  # [batch, C, seq_len]
```

### 2. åˆ†æ®µåŠ æƒæŸå¤±

é’ˆå¯¹ e å€¼åˆ†å¸ƒçš„é•¿å°¾ç‰¹æ€§,é‡‡ç”¨åˆ†æ®µæƒé‡:

```python
# config.yaml
loss:
  threshold_1: 10000.0    # e < 10000 (å¸¸è§å€¼)
  threshold_2: 30000.0    # e â‰¥ 30000 (å¼‚å¸¸é«˜å€¼)
  low_weight: 1           # å¸¸è§å€¼æƒé‡
  mid_weight: 1           # ä¸­ç­‰å€¼æƒé‡
  high_weight: 1          # å¼‚å¸¸å€¼æƒé‡ (å¯é™ä½ä»¥å‡å°‘æ‹Ÿåˆ)
```

è¿™æ ·å¯ä»¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆåˆ°æç«¯é«˜ e å€¼æ ·æœ¬ã€‚

### 3. å¤šæ¨¡å‹é›†æˆ

```python
# åŠ è½½å¤šä¸ªæ¨¡å‹
models = [
    load_model(model_path_1, config_path_1, device),
    load_model(model_path_2, config_path_2, device),
    load_model(model_path_3, config_path_3, device),
]

# é›†æˆé¢„æµ‹
predictions = []
for model, dataset, config in models:
    pred = predict_effusivity(model, temp_seq, dataset, device)
    predictions.append(pred)

# å¹³å‡æˆ–åŠ æƒå¹³å‡
final_pred = np.mean(predictions)
# æˆ– final_pred = np.average(predictions, weights=[0.5, 0.3, 0.2])
```

### 4. ä¸ç¡®å®šæ€§é‡åŒ– (VAE æ¨¡å‹)

VAE æ¨¡å‹å¤©ç„¶æ”¯æŒä¸ç¡®å®šæ€§ä¼°è®¡:

```python
# å¤šæ¬¡é‡‡æ ·
n_samples = 100
predictions = []

model.eval()
with torch.no_grad():
    for _ in range(n_samples):
        recon, e_pred, (mu, logvar), x_smooth = model(temp_tensor)
        predictions.append(e_pred.item())

# ç»Ÿè®¡
mean_pred = np.mean(predictions)
std_pred = np.std(predictions)
conf_interval = (
    mean_pred - 1.96 * std_pred,  # 95%ç½®ä¿¡åŒºé—´ä¸‹é™
    mean_pred + 1.96 * std_pred   # 95%ç½®ä¿¡åŒºé—´ä¸Šé™
)

print(f"é¢„æµ‹: {mean_pred:.2f} Â± {std_pred:.2f}")
print(f"95%ç½®ä¿¡åŒºé—´: [{conf_interval[0]:.2f}, {conf_interval[1]:.2f}]")
```

## æ€§èƒ½ä¼˜åŒ–

### è®­ç»ƒåŠ é€Ÿ

1. **å¢å¤§ batch_size** (åœ¨æ˜¾å­˜å…è®¸çš„æƒ…å†µä¸‹)
   ```yaml
   data:
     batch_size: 8192  # é»˜è®¤4096
   ```

2. **å‡å°‘æ¨¡å‹å¤æ‚åº¦**
   ```yaml
   model:
     timevae1d_hybrid_mamba_transformer_residual:
       d_model: 128     # ä»256å‡å°
       n_mamba: 2       # ä»3å‡å°
       n_transformer: 2 # ä»3å‡å°
   ```

3. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ** (éœ€è¦ PyTorch >= 1.6)
   ```python
   from torch.cuda.amp import autocast, GradScaler
   
   scaler = GradScaler()
   
   with autocast():
       loss = model(...)
   
   scaler.scale(loss).backward()
   scaler.step(optimizer)
   scaler.update()
   ```

### æ¨ç†åŠ é€Ÿ

1. **æ¨¡å‹é‡åŒ–** (INT8)
   ```python
   quantized_model = torch.quantization.quantize_dynamic(
       model, {nn.Linear}, dtype=torch.qint8
   )
   ```

2. **ONNX å¯¼å‡º**
   ```python
   dummy_input = torch.randn(1, 1, 151).to(device)
   torch.onnx.export(
       model, dummy_input, "model.onnx",
       input_names=['temperature'],
       output_names=['effusivity'],
       dynamic_axes={'temperature': {0: 'batch_size'}}
   )
   ```

## å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ:**
1. å‡å° `batch_size`
2. å‡å°æ¨¡å‹ `d_model` æˆ–å±‚æ•°
3. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯:
   ```python
   accumulation_steps = 4
   for i, batch in enumerate(dataloader):
       loss = model(...) / accumulation_steps
       loss.backward()
       if (i + 1) % accumulation_steps == 0:
           optimizer.step()
           optimizer.zero_grad()
   ```

### Q2: é¢„æµ‹å€¼å¼‚å¸¸é«˜ (e > 30000)

**å¯èƒ½åŸå› :**
1. æ¨¡å‹è¿‡æ‹Ÿåˆåˆ°å¼‚å¸¸æ ·æœ¬
2. æ¸©åº¦æ•°æ®æœªæ­£ç¡®å½’ä¸€åŒ–
3. åºåˆ—é•¿åº¦ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ:**
1. è°ƒæ•´åˆ†æ®µæƒé‡,é™ä½ `high_weight`
2. æ£€æŸ¥æ•°æ®é¢„å¤„ç†æµç¨‹
3. ç¡®ä¿è¾“å…¥åºåˆ—æ’å€¼åˆ°æ­£ç¡®é•¿åº¦

### Q3: VAE é‡å»ºæ•ˆæœå·®

**å¯èƒ½åŸå› :**
1. `latent_dim` è¿‡å°,ä¿¡æ¯ç“¶é¢ˆ
2. `beta` (KLæƒé‡) è¿‡å¤§,åéªŒåç¼©
3. è®­ç»ƒä¸å……åˆ†

**è§£å†³æ–¹æ¡ˆ:**
1. å¢å¤§ `latent_dim` (64 â†’ 128 â†’ 256)
2. é™ä½ `beta` (0.01 â†’ 0.001)
3. å¢åŠ è®­ç»ƒè½®æ¬¡æˆ–é™ä½å­¦ä¹ ç‡

### Q4: å¤šGPUè®­ç»ƒæ—¶å‡ºé”™

**æ£€æŸ¥é¡¹:**
1. ç¡®è®¤æ‰€æœ‰GPUå¯è§: `echo $CUDA_VISIBLE_DEVICES`
2. æ£€æŸ¥æ˜¾å­˜æ˜¯å¦å……è¶³: `nvidia-smi`
3. ç¡®ä¿ PyTorch ç¼–è¯‘æ—¶å¯ç”¨äº† CUDA

**è°ƒè¯•å‘½ä»¤:**
```bash
# å•GPUæµ‹è¯•
CUDA_VISIBLE_DEVICES=0 python train.py

# é€æ­¥å¢åŠ GPUæ•°é‡
CUDA_VISIBLE_DEVICES=0,1 python train.py
```

## é¡¹ç›®è´¡çŒ®

### æ¨¡å‹å¼€å‘è€…

- **Transformer ç³»åˆ—**: TimeTransformer, PhysicsInformedTransformer, EnhancedPhysicsTransformer
- **Mamba ç³»åˆ—**: MambaPhysicsModel, EnhancedMambaPhysicsModel, HybridMambaTransformer
- **VAE ç³»åˆ—**: TimeVAE1D_Mamba, TimeVAE1D_HybridMambaTransformer_Residual, TimeVAE1D_StageAware

### å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©,è¯·è€ƒè™‘å¼•ç”¨:

```bibtex
@software{point_lg_2024,
  title = {Point_lg: Deep Learning Framework for Thermal Parameter Prediction},
  author = {Your Name},
  year = {2024},
  url = {https://github.com/yourusername/Point_lg}
}
```

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ `LICENSE` æ–‡ä»¶ã€‚

## è”ç³»æ–¹å¼

- ä½œè€…: [æ‚¨çš„å§“å]
- Email: [æ‚¨çš„é‚®ç®±]
- GitHub: [é¡¹ç›®åœ°å€]

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-12-24)
- âœ… åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… å®ç° 10+ ç§æ¨¡å‹æ¶æ„
- âœ… æ”¯æŒå¤šGPUè®­ç»ƒ
- âœ… å®Œå–„çš„æ•°æ®é¢„å¤„ç†æµç¨‹
- âœ… åˆ†æ®µåŠ æƒæŸå¤±å‡½æ•°
- âœ… VAE æ®‹å·®é‡å»ºæœºåˆ¶
- âœ… GIF æ‰¹é‡é¢„æµ‹åŠŸèƒ½

---

**Happy Modeling! ğŸš€**
